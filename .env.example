# WanVidGen Environment Configuration
# Copy this file to .env and customize the values for your setup

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================

# Path to the model file (GGUF, PyTorch, or other supported formats)
# Example: ./models/wan2.1-gguf-q5.bin
WANVIDGEN_MODEL_PATH=

# Model name identifier for display and logging
# Example: wan2.1-gguf-q5
WANVIDGEN_MODEL_NAME=

# Model precision setting
# Options: Q5, Q6, FP16, FP32
# Q5/Q6 for quantized models, FP16/FP32 for full precision
WANVIDGEN_PRECISION=Q5

# Compute device for model inference
# Options: auto (automatic detection), cpu, cuda (NVIDIA GPU), mps (Apple Silicon)
WANVIDGEN_DEVICE=auto

# GPU device ID (for multi-GPU systems)
# Example: 0 (use first GPU), 1 (use second GPU), etc.
# Leave empty or set to -1 for automatic selection
WANVIDGEN_GPU_ID=

# Model context length (maximum sequence length)
# Example: 2048, 4096, 8192
WANVIDGEN_CONTEXT_LENGTH=2048

# Maximum tokens to generate
# Example: 512, 1024
WANVIDGEN_MAX_TOKENS=512


# =============================================================================
# OUTPUT CONFIGURATION
# =============================================================================

# Directory where generated videos and files will be saved
# Example: ./outputs, /tmp/wanvidgen_outputs
WANVIDGEN_OUTPUT_DIR=./outputs

# Output video format
# Options: mp4 (recommended), avi, mov, mkv
WANVIDGEN_VIDEO_FORMAT=mp4

# Video frames per second
# Options: 24, 30, 60 (higher values = smoother but larger files)
WANVIDGEN_FPS=30

# Video width in pixels
# Must be even number. Common values: 512, 1024, 1920
WANVIDGEN_WIDTH=1024

# Video height in pixels  
# Must be even number. Common values: 288, 576, 1080
WANVIDGEN_HEIGHT=576

# Video quality preset
# Options: low (smaller files), medium, high (recommended), ultra (largest files)
WANVIDGEN_QUALITY=high

# Video compression level
# Options: none (uncompressed), low, medium (recommended), high (maximum compression)
WANVIDGEN_COMPRESSION=medium


# =============================================================================
# PIPELINE CONFIGURATION
# =============================================================================

# Batch size for model inference
# Higher values = faster generation but more memory usage
# Example: 1 (conservative), 2, 4 (high-end systems)
WANVIDGEN_BATCH_SIZE=1

# Number of worker processes for data loading
# Should be less than or equal to CPU cores
# Example: 4 (for 8-core system)
WANVIDGEN_NUM_WORKERS=4

# Prefetch factor for data loading
# Number of batches to prefetch (higher = more memory, potentially faster)
WANVIDGEN_PREFETCH_FACTOR=2

# Pin memory in DataLoader (GPU training optimization)
# Options: true (faster GPU transfer), false
WANVIDGEN_PIN_MEMORY=true

# Keep worker processes alive between epochs
# Options: true (faster startup), false (lower memory usage)
WANVIDGEN_PERSISTENT_WORKERS=false

# Timeout for pipeline operations (seconds)
# Increase if generating large videos or on slow systems
WANVIDGEN_TIMEOUT=30


# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================

# Logging level
# Options: DEBUG (most verbose), INFO (recommended), WARNING, ERROR, CRITICAL
WANVIDGEN_LOG_LEVEL=INFO

# Log message format
# Uses Python logging format string syntax
# Example: %(asctime)s - %(name)s - %(levelname)s - %(message)s
WANVIDGEN_LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s

# Enable file logging
# Options: true (write logs to file), false (console only)
WANVIDGEN_FILE_LOGGING=false

# Log file path (if file logging is enabled)
# Example: ./logs/wanvidgen.log
WANVIDGEN_LOG_FILE=./logs/wanvidgen.log

# Enable console logging
# Options: true (show logs in terminal), false
WANVIDGEN_CONSOLE_LOGGING=true


# =============================================================================
# APPLICATION CONFIGURATION
# =============================================================================

# Enable debug mode
# Options: true (verbose logging, additional checks), false (production mode)
WANVIDGEN_DEBUG=false

# Enable graphical user interface
# Options: true (start GUI), false (command-line only)
WANVIDGEN_GUI_ENABLED=true

# Custom environment file path
# Path to a custom .env file (if different from default .env)
# Leave empty to use default .env file in current directory
WANVIDGEN_ENV_FILE=


# =============================================================================
# PERFORMANCE TUNING (OPTIONAL)
# =============================================================================

# Memory mapping for model files (can speed up loading)
# Options: true, false
# WANVIDGEN_MEMORY_MAP=false

# Use custom memory allocator (PyTorch performance tuning)
# Options: true, false
# WANVIDGEN_MEMORY_ALLOCATOR=

# Enable model compilation (PyTorch 2.0+ performance optimization)
# Options: true, false
# WANVIDGEN_COMPILE_MODEL=false

# Number of threads for CPU operations
# Leave empty to use default (typically equal to CPU cores)
# WANVIDGEN_CPU_THREADS=


# =============================================================================
# DEVELOPMENT OPTIONS (OPTIONAL)
# =============================================================================

# Enable profiling for performance analysis
# Options: true, false
# WANVIDGEN_PROFILE=false

# Profiling output directory
# Example: ./profiling
# WANVIDGEN_PROFILE_DIR=./profiling

# Enable experimental features
# Options: true, false
# WANVIDGEN_EXPERIMENTAL=false

# Save intermediate outputs during generation
# Options: true (for debugging), false (production)
# WANVIDGEN_SAVE_INTERMEDIATES=false
